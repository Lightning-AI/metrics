# Create and test a Python package on multiple dependencies versions.

trigger:
  tags:
    include:
      - '*'
  branches:
    include:
      - master
      - release/*
      - refs/tags/*
pr:
  - master
  - release/*

jobs:
  - job: integrate
    strategy:
      matrix:
        'oldest':
          docker-image: 'pytorch/pytorch:1.11.0-cuda11.3-cudnn8-runtime'
          torch-ver: '1.11.0'
        'latest':
          docker-image: 'pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime'
          torch-ver: '2.0.0'
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "40"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"
    pool: "lit-rtx-3090"
    variables:
      DEVICES: $( python -c 'name = "$(Agent.Name)" ; gpus = name.split("_")[-1] if "_" in name else "0,1"; print(gpus)' )
      # these two caches assume to run repetitively on the same set of machines
      TORCH_HOME: "/var/tmp/torch"
      TRANSFORMERS_CACHE: "/var/tmp/huggingface"
      PIP_CACHE_DIR: "/var/tmp/pip"
    container:
      image: "$(docker-image)"
      options: "--gpus=all --shm-size=8g -v /usr/bin/docker:/tmp/docker:ro  -v /var/tmp:/var/tmp"
    workspace:
      clean: all
    steps:

    - bash: |
        echo "##vso[task.setvariable variable=CUDA_VISIBLE_DEVICES]$(DEVICES)"
        CUDA_version=$(nvcc --version | sed -n 's/^.*release \([0-9]\+\.[0-9]\+\).*$/\1/p')
        CUDA_version_mm="${CUDA_version//'.'/''}"
        echo "##vso[task.setvariable variable=CUDA_VERSION_MM]$CUDA_version_mm"
        echo "##vso[task.setvariable variable=TORCH_URL]https://download.pytorch.org/whl/cu${CUDA_version_mm}/torch_stable.html"
      displayName: 'set Env. vars'

    - bash: |
        whoami && id
        lspci | egrep 'VGA|3D'
        whereis nvidia
        nvidia-smi
        echo $CUDA_VISIBLE_DEVICES
        echo $TORCH_URL
        python --version
        pip --version
        pip cache dir
        pip list
      displayName: 'Image info & NVIDIA'

    - bash: |
        set -e
        pip install -q packaging fire requests wget
        python -m wget https://raw.githubusercontent.com/Lightning-AI/utilities/main/scripts/adjust-torch-versions.py
        python adjust-torch-versions.py requirements.txt $(torch-ver)
        python adjust-torch-versions.py requirements/integrate.txt $(torch-ver)
        python .github/assistant.py set-oldest-versions --req_files='["requirements/integrate.txt"]'
        cat requirements/integrate.txt
      displayName: 'Adjust versions'

    - bash: |
        set -ex
        pip install -q -r requirements/integrate.txt
        # force reinstall TM as it could be overwritten by integration's dependencies
        pip install . -U -r requirements/test.txt --find-links ${TORCH_URL}
        pip list
      displayName: 'Install package & integrations'

    - bash: |
        set -e
        python -c "from torch import __version__ as ver ; assert str(ver).split('+')[0] == '$(torch-ver)', f'PyTorch: {ver}'"
        python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu >= 2, f'found GPUs: {mgpu}'"
      displayName: 'Sanity check'

    - bash: python -m pytest integrations -v --durations=25
      env:
        PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: 'python'
      workingDirectory: tests
      displayName: 'Test integrations'
