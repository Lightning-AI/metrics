# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
  tags:
    include:
      - '*'
  branches:
    include:
      - master
      - release/*
      - refs/tags/*
pr:
  - master
  - release/*

jobs:
  - job: pytest
    strategy:
      matrix:
        'PyTorch - old':
          docker-image: 'pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime'
          agent-pool: 'lit-rtx-3090'
          torch-ver: '1.9.0'
        'PyTorch - stable':
          docker-image: 'pytorch/pytorch:1.13.0-cuda11.6-cudnn8-runtime'
          agent-pool: 'lit-rtx-3090'
          torch-ver: '1.13.0'
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "95"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"

    pool: "$(agent-pool)"

    variables:
      DEVICES: $( python -c 'name = "$(Agent.Name)" ; gpus = name.split("_")[-1] if "_" in name else "0,1"; print(gpus)' )
      HF_CACHE_DIR: "$(Pipeline.Workspace)/ci-cache_huggingface"

    container:
      image: "$(docker-image)"
      options: "--gpus=all --shm-size=8g -v /usr/bin/docker:/tmp/docker:ro"

    workspace:
      clean: all

    steps:

    - bash: |
        echo "##vso[task.setvariable variable=CONTAINER_ID]$(head -1 /proc/self/cgroup|cut -d/ -f3)"
        echo "##vso[task.setvariable variable=CUDA_VISIBLE_DEVICES]$(DEVICES)"
      displayName: 'Set environment variables'

    - bash: |
        whoami && id
        lspci | egrep 'VGA|3D'
        whereis nvidia
        nvidia-smi
        echo $CUDA_VISIBLE_DEVICES
        echo $CONTAINER_ID
        python --version
        pip --version
        pip list
        python -c "import torch ; print(torch.cuda.get_arch_list())"
      displayName: 'Image info & NVIDIA'

    - script: |
        /tmp/docker exec -t -u 0 $CONTAINER_ID \
        sh -c "apt-get update && DEBIAN_FRONTEND=noninteractive apt-get -o Dpkg::Options::="--force-confold" -y install sudo"
      displayName: 'Install Sudo in container (thanks Microsoft!)'

    - bash: |
        pip install -q packaging
        python ./requirements/adjust-versions.py requirements.txt
        for fpath in `ls requirements/*.txt`; do
            python ./requirements/adjust-versions.py $fpath
        done
      displayName: 'Adjust versions'

    - bash: |
        set -ex
        sudo apt-get update -qq --fix-missing
        sudo apt-get install -y build-essential gcc g++ cmake ffmpeg git libsndfile1 unzip --no-install-recommends
        pip install pip -U
        pip install -e . -r ./requirements/devel.txt
        # pip install pandas --force-reinstall  # fixing some strange numpy erro for oldest config.
        pip install mkl-service==2.4.0  # needed for the gpu multiprocessing
        pip list
      displayName: 'Install environment'

    - bash: |
        set -e
        python -c "from torch import __version__ as ver ; assert str(ver).split('+')[0] == '$(torch-ver)', f'PyTorch: {ver}'"
        python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu >= 2, f'GPU: {mgpu}'"
      displayName: 'Sanity check'

    - task: Cache@2
      inputs:
        key: transformers | "$(Agent.OS)"
        restoreKeys: transformers
        path: $(HF_CACHE_DIR)
        cacheHitVar: HF_CACHE_RESTORED
    - bash: |
        printf "cache location: $(HF_CACHE_DIR)\n"
        printf "hit the HF cache: $(variables.HF_CACHE_RESTORED)\n"
        mkdir -p $(HF_CACHE_DIR)  # in case cache was void
        ls -lh $(HF_CACHE_DIR)  # show what was restored...
      displayName: 'Show HF cache'

    - bash: python -m pytest torchmetrics --cov=torchmetrics --timeout=150 --durations=50
      workingDirectory: src
      displayName: 'DocTesting'

    - bash: |
        # wget is simpler but does not work on Windows
        python -c "from urllib.request import urlretrieve ; urlretrieve('https://pl-public-data.s3.amazonaws.com/metrics/data.zip', 'data.zip')"
        unzip -o data.zip
        ls -l _data/*
      workingDirectory: tests
      displayName: 'Pull testing data from S3'

    - bash: |
        python -m pytest unittests -v --cov=torchmetrics --junitxml=$(Build.StagingDirectory)/test-results.xml --timeout=150 --durations=50
      env:
        CUDA_LAUNCH_BLOCKING: 1
      workingDirectory: tests
      displayName: 'UnitTesting'

    - bash: |
        python -m coverage report
        python -m coverage xml
        python -m codecov --token=$(CODECOV_TOKEN) --commit=$(Build.SourceVersion) --flags=gpu,unittest --name="GPU-coverage" --env=linux,azure
        ls -l
      workingDirectory: tests
      env:
        TRANSFORMERS_CACHE: $(HF_CACHE_DIR)
      displayName: 'Statistics'

    - task: PublishTestResults@2
      displayName: 'Publish test results'
      inputs:
        testResultsFiles: '$(Build.StagingDirectory)/test-results.xml'
        testRunTitle: '$(Agent.OS) - $(Build.DefinitionName) - Python $(python.version)'
      condition: succeededOrFailed()
      # if future steps should run even if this step fails
      continueOnError: true

    # todo: re-enable after schema check pass, also atm it seems does not have any effect
    #- task: PublishCodeCoverageResults@1
    #  displayName: 'Publish coverage report'
    #  inputs:
    #    codeCoverageTool: 'Cobertura'
    #    summaryFileLocation: '$(Build.SourcesDirectory)/coverage.xml'
    #    reportDirectory: '$(Build.SourcesDirectory)/htmlcov'
    #    testRunTitle: '$(Agent.OS) - $(Build.BuildNumber)[$(Agent.JobName)] - Python $(python.version)'
    #  condition: succeededOrFailed()

    - bash: |
        set -e
        FILES="*.py"
        for fn in $FILES
        do
          echo "Processing $fn example..."
          python $fn
        done
      workingDirectory: examples
      displayName: 'Examples'

    - bash: |
        pip install -q fire requests
        python .github/assistant.py set-oldest-versions --req_files='["requirements/integrate.txt"]'
        cat requirements/integrate.txt
      displayName: 'Set oldest versions'
      condition: eq(variables['torch-ver'], '1.9.0')

    - bash: |
        pip install -q -r requirements/integrate.txt
        pip install -e .  # force reinstall TM as it could be overwritten by integration's depenencies
        pip list
      displayName: 'Install integrations'

    - bash: python -m pytest integrations -v --durations=25
      env:
        PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: 'python'
      workingDirectory: tests
      displayName: 'Test integrations'
